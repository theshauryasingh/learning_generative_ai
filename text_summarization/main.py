import streamlit as st
from langchain.text_splitter import CharacterTextSplitter # used for splitter the text into smalle chunks
from langchain.docstore.document import Document # convert the chunks in document format
from langchain.chains.summarize import load_summarize_chain # connect prompt and llm model
from langchain import PromptTemplate # for creating prompt 
from langchain.llms import CTransformers # loading the llm model
from langchain.callbacks.manager import CallbackManager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

# this function is responsible for splitting the data into smaller chunks and convert the data in document format
def chunks_and_document(txt):
    text_splitter = CharacterTextSplitter() # text splitter method by default it has chunk_size = 200 and chunk_overlap = 200
    texts = text_splitter.split_text(txt) # split the text into smaller chunks
    docs = [Document(page_content=t) for t in texts] # convert the splitted chunks into document format
    return docs


# Loading the Llama 2's LLM
def load_llm():
    # We instantiate the callback with a streaming stdout handler
    callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])   

    # loading the LLM model
    # This open source model can be downloaded from here
    # Their are multiple models available just replace it in place of model and try it.
    llm = CTransformers(
        model="/home/nmrui/shaurya/learning_LLM/Llama-2-7B-Chat-GGML/llama-2-7b-chat.ggmlv3.q4_1.bin", #q4_1 #q2_K
        model_type="llama",
         max_new_tokens = 512,
        temperature = 0.5   )
        
    return llm

# this functions is used for applying the llm model with our document 
def chains_and_response(docs):
    
    llm = load_llm()
    chain = load_summarize_chain(llm,chain_type='map_reduce')
    
    return chain.run(docs)

# Page title
st.set_page_config(page_title='ü¶úüîó Text Summarization App')
st.title('ü¶úüîó Text Summarization App')

# Text input
txt_input = st.text_area('Enter your text', '', height=200)

# Form to accept user's text input for summarization
result = []
with st.form('summarize_form', clear_on_submit=True):
    submitted = st.form_submit_button('Submit')
    #if submitted and openai_api_key.startswith('sk-'):
    if submitted:
        with st.spinner('Calculating...'):
            docs = chunks_and_document(txt_input)
            response = chains_and_response(docs)
            result.append(response)

if len(result):
    st.title('üìù‚úÖ Summarization Result')
    st.info(response)

